{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import Scrollbar, Text, filedialog, messagebox\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import spacy\n",
    "import subprocess\n",
    "import threading\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tkinter import filedialog\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import speech_recognition as sr\n",
    "from deepface import DeepFace\n",
    "from PIL import Image, ImageTk\n",
    "import pyaudio\n",
    "import pyttsx3\n",
    "import requests\n",
    "from fuzzywuzzy import fuzz\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_silence\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Cargar el modelo desde el archivo .h5\n",
    "model = load_model('mejor_modelo.h5')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Cargar el modelo de emociones\n",
    "emociones_model = load_model('emotion_model.h5')\n",
    "emociones_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "API_URL = 'https://magicloops.dev/api/loop/22dfbc51-f14c-4332-a9c5-4e6e7ebc5305/run'\n",
    "\n",
    "### Paleta de colores ###\n",
    "\n",
    "COLOR_FONDO_PRINCIPAL = \"#E3F2FD\"  # Azul claro\n",
    "COLOR_FONDO_SECUNDARIO = \"#90CAF9\"  # Azul más oscuro\n",
    "COLOR_TEXTO_PRINCIPAL = \"#212121\"  # Gris oscuro\n",
    "COLOR_BOTONES = \"#42A5F5\"  # Azul medio\n",
    "COLOR_BOTONES_HOVER = \"#64B5F6\"  # Azul más claro\n",
    "COLOR_BORDES = \"#BDBDBD\"  # Gris claro\n",
    "\n",
    "# ==================================================\n",
    "# Configuración del Chatbot\n",
    "# ==================================================\n",
    "\n",
    "class ChatbotApp:\n",
    "    def __init__(self, window):\n",
    "        self.window = window\n",
    "        # Frame del chatbot\n",
    "        self.chatbot_frame = tk.LabelFrame(window, text=\"Chatbot de Alzheimer\", font = (\"Times New Roman\", 25), bg=COLOR_FONDO_PRINCIPAL,\n",
    "            fg=COLOR_TEXTO_PRINCIPAL,\n",
    "            relief=tk.RAISED,\n",
    "            borderwidth=2\n",
    "        )\n",
    "        self.chatbot_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "\n",
    "        # Scrollbar\n",
    "        self.scrollbar = Scrollbar(self.chatbot_frame)\n",
    "        self.chatbox = Text(\n",
    "            self.chatbot_frame,\n",
    "            height=15,\n",
    "            width=60,\n",
    "            yscrollcommand=self.scrollbar.set,\n",
    "            font = (\"Times New Roman\", 20),\n",
    "            bg=\"white\",\n",
    "            fg=COLOR_TEXTO_PRINCIPAL,\n",
    "            relief=tk.SUNKEN,\n",
    "            borderwidth=2\n",
    "            )\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        self.chatbox.pack(side = tk.TOP, fill = tk.BOTH, expand = True)\n",
    "\n",
    "### Deshabilitar la edición ###\n",
    "        self.chatbox.config(state = \"disabled\")\n",
    "\n",
    "        ### Configurar etiquetas (tags) para alinear los mensajes ###\n",
    "        self.chatbox.tag_configure(\"user\",justify = \"right\", background= \"#DCF8C6\", relief = \"raised\", borderwidth = 2)\n",
    "        self.chatbox.tag_configure(\"bot\", justify=\"left\", background=\"#ECECEC\", relief=\"raised\", borderwidth=2)\n",
    "\n",
    "        # Campo de entrada y botón de envío\n",
    "        self.entry_frame = tk.Frame(self.chatbot_frame, bg=COLOR_FONDO_PRINCIPAL)\n",
    "        self.entry_frame.pack(side = tk.BOTTOM, fill = tk.X, padx = 5, pady = 5)\n",
    "        \n",
    "        self.indicativo_label = tk.Label(\n",
    "            self.entry_frame,\n",
    "            text = \"Escribe tu mensaje aquí: \",\n",
    "            font = (\"Times New Roman\", 16),\n",
    "            bg=COLOR_FONDO_PRINCIPAL,\n",
    "            fg=COLOR_TEXTO_PRINCIPAL\n",
    "            )\n",
    "        self.indicativo_label.pack(side = tk.TOP, anchor = tk.W, pady = (0, 5))\n",
    "\n",
    "        ### Frame para el campo de entrada y el botón (dentro del entry_frame)###\n",
    "        self.input_frame = tk.Frame(self.entry_frame, bg=COLOR_FONDO_PRINCIPAL)\n",
    "        self.input_frame.pack(side = tk.TOP, fill = tk.X)\n",
    "\n",
    "        self.entry = tk.Entry(\n",
    "            self.input_frame,\n",
    "            width=50,\n",
    "            font = (\"Times New Roman\", 20),\n",
    "            bg = \"white\",\n",
    "            fg = COLOR_TEXTO_PRINCIPAL,\n",
    "            relief = tk.SUNKEN,\n",
    "            borderwidth = 2\n",
    "            )\n",
    "        \n",
    "        self.entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.send_button = tk.Button(\n",
    "            self.input_frame,\n",
    "            text=\"Enviar\",\n",
    "            command=self.send_message,\n",
    "            font = (\"Times New Roman\", 16)\n",
    "            )\n",
    "        self.send_button.pack(side = tk.RIGHT)\n",
    "\n",
    "        # Enviar mensaje al presionar Enter\n",
    "        self.entry.bind(\"<Return>\", lambda event: self.send_message())\n",
    "\n",
    "    def send_message(self):\n",
    "        user_text = self.entry.get().strip()\n",
    "        if user_text:\n",
    "\n",
    "            ### Habilitar temporalmente para insertar texto ###\n",
    "            self.chatbox.config(state = \"normal\" )\n",
    "\n",
    "            ### Mostrar la pregunta en el chat (Alineado a la derecha)###\n",
    "            self.chatbox.insert(tk.END, f\"Tú: {user_text}\\n\", \"user\")\n",
    "\n",
    "            ### Desplazar al final del chat###\n",
    "            self.chatbox.see(tk.END)\n",
    "\n",
    "            ### Enviar la pregunta a la API ###\n",
    "            response_text = self.get_response_from_api(user_text)\n",
    "\n",
    "            ### Mostrar la respuesta en el chat (Alineado a la izquierda)###\n",
    "            self.chatbox.insert(tk.END, f\"Bot: {response_text}\\n\\n\", \"bot\")\n",
    "\n",
    "            ### Desplazar al final del chat ###\n",
    "            self.chatbox.see(tk.END)  \n",
    "\n",
    "            ### Deshabilitar de nuevo ###\n",
    "            self.chatbox.config(state = \"disabled\")\n",
    "\n",
    "            ### Limpiar el campo de entrada ###\n",
    "            self.entry.delete(0, tk.END)\n",
    "\n",
    "    def get_response_from_api(self, question):\n",
    "        ### Lista de saludos comunes ###\n",
    "        saludos = [\"hola\", \"holis\", \"buenos días\", \"buenas tardes\", \"buenas noches\", \"hi\", \"hello\", \"que tal\", \"cómo estás\"]\n",
    "\n",
    "        ### Convertir la pregunta a minúsculas para hacer la comparación insensible a mayúsculas ###\n",
    "        question_lower = question.lower()\n",
    "\n",
    "        ### Verificar si la pregunta contiene un saludo (incluso con errores tipográficos) ###\n",
    "        contiene_saludo = any(fuzz.partial_ratio(saludo, question_lower) > 80 for saludo in saludos)\n",
    "        \n",
    "        ### Si contiene un saludo, responder con un saludo amigable ###\n",
    "        if contiene_saludo:\n",
    "            respuesta_saludo = \"¡Hola! Soy un chatbot diseñado para ayudarte con información sobre el Alzheimer. ¿En qué puedo ayudarte hoy?\"\n",
    "\n",
    "            ### Si la pregunta contiene algo más aparte del saludo, responder también a eso ###\n",
    "            if len(question_lower.split()) > 2: ### Si hay más de dos palabras, asumimos que hay una pregunta###\n",
    "\n",
    "        ### Si no es un saludo, enviar la pregunta a la API###\n",
    "\n",
    "                try:\n",
    "                    payload = {\"question\": question}\n",
    "                    response = requests.get(API_URL, json = payload)\n",
    "\n",
    "            # Verificar si la respuesta es un JSON válido\n",
    "                    try:\n",
    "                        response_json = response.json()  # Intenta convertir la respuesta a JSON\n",
    "                        \n",
    "                        if isinstance(response_json, dict):  # Si es un diccionario\n",
    "\n",
    "                            respuesta_api = response_json.get(\"response\", \"Lo siento, no pude obtener una respuesta.\")\n",
    "\n",
    "                        elif isinstance(response_json, list) and len(response_json) > 0:  # Si es una lista\n",
    "                            respuesta_api = response_json[0].get(\"response\", \"Lo siento, no pude obtener una respuesta.\")\n",
    "                        \n",
    "                        else:\n",
    "                            # Si la respuesta no es un diccionario ni una lista, devolver el texto directamente\n",
    "                            respuesta_api = str(response_json)\n",
    "\n",
    "                    except ValueError:  # Si no se puede convertir a JSON\n",
    "\n",
    "                        # Si la respuesta no es un JSON válido, devolver el texto directamente\n",
    "                        respuesta_api = response.text\n",
    "\n",
    "                except requests.RequestException as e:\n",
    "                    return f\"Error: No se pudo conectar con el servidor. Detalles: {str(e)}\"\n",
    "            \n",
    "            else:\n",
    "            # Si solo es un saludo, devolver solo el saludo\n",
    "                return respuesta_saludo\n",
    "\n",
    "    # Si no es un saludo, enviar la pregunta a la API\n",
    "        try:\n",
    "            payload = {\"question\": question}\n",
    "            response = requests.get(API_URL, json=payload)\n",
    "\n",
    "            # Verificar si la respuesta es un JSON válido\n",
    "            try:\n",
    "                response_json = response.json()  # Intenta convertir la respuesta a JSON\n",
    "                if isinstance(response_json, dict):  # Si es un diccionario\n",
    "                    return response_json.get(\"response\", \"Lo siento, no pude obtener una respuesta.\")\n",
    "                elif isinstance(response_json, list) and len(response_json) > 0:  # Si es una lista\n",
    "                    return response_json[0].get(\"response\", \"Lo siento, no pude obtener una respuesta.\")\n",
    "                else:\n",
    "                    # Si la respuesta no es un diccionario ni una lista, devolver el texto directamente\n",
    "                    return str(response_json)\n",
    "            except ValueError:  # Si no se puede convertir a JSON\n",
    "\n",
    "    # Si la respuesta no es un JSON válido, devolver el texto directamente\n",
    "                return response.text\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            return f\"Error: No se pudo conectar con el servidor. Detalles: {str(e)}\"\n",
    "\n",
    "# ==================================================\n",
    "# Configuración del Monitoreo\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "def calcular_velocidad_habla(texto, tiempo_transcurrido):\n",
    "    palabras = texto.split()\n",
    "    if tiempo_transcurrido > 0:\n",
    "        velocidad = len(palabras) / tiempo_transcurrido  # Palabras por segundo\n",
    "        return velocidad\n",
    "    return 0\n",
    "\n",
    "\n",
    "def filtrar_ruido(audio_path, output_path=\"audio_filtrado.wav\"):\n",
    "    # Cargar el audio\n",
    "    audio, rate = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Reducir el ruido\n",
    "    audio_filtrado = nr.reduce_noise(y=audio, sr=rate)\n",
    "\n",
    "    # Guardar el audio filtrado\n",
    "    sf.write(output_path, audio_filtrado, rate)\n",
    "    return output_path\n",
    "\n",
    "# Ejemplo de uso\n",
    "audio_path = \"temp_audio.wav\"\n",
    "audio_filtrado_path = filtrar_ruido(audio_path)\n",
    "\n",
    "\n",
    "def detectar_pausas_largas(audio_path, umbral_silencio=-50, duracion_minima_pausa=3000):\n",
    "    # Cargar el archivo de audio\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "    # Detectar silencios\n",
    "    silencios = detect_silence(audio, min_silence_len=duracion_minima_pausa, silence_thresh=umbral_silencio)\n",
    "\n",
    "    # Calcular la duración total de las pausas\n",
    "    duracion_total_pausas = sum(fin - inicio for inicio, fin in silencios)\n",
    "    return duracion_total_pausas / 1000  # Convertir a segundos\n",
    "\n",
    "\n",
    "\n",
    "def detectar_retraso_en_habla(texto, tiempo_transcurrido, audio):\n",
    "    if not texto:  # Si no hay texto, no hay alerta\n",
    "        return None\n",
    "\n",
    "    # Calcular velocidad del habla\n",
    "    velocidad = calcular_velocidad_habla(texto, tiempo_transcurrido)\n",
    "    \n",
    "    # Detectar pausas largas\n",
    "    duracion_pausas = detectar_pausas_largas(audio)\n",
    "    \n",
    "    # Umbrales ajustados\n",
    "    umbral_velocidad = 0.8  # Menos de 0.8 palabras por segundo\n",
    "    umbral_pausas = 4.0     # Pausas de más de 4 segundos\n",
    "    \n",
    "    alertas = []\n",
    "    if velocidad < umbral_velocidad:\n",
    "        alertas.append(f\"Velocidad del habla muy lenta ({velocidad:.1f} palabras/segundo).\")\n",
    "    if duracion_pausas > umbral_pausas:\n",
    "        alertas.append(f\"Pausas largas detectadas ({duracion_pausas:.1f} segundos).\")\n",
    "    \n",
    "    if alertas:\n",
    "        return \"Alerta: Posible retraso en el habla. \" + \" \".join(alertas)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def analizar_fluidez(texto, tiempo_transcurrido):\n",
    "    palabras = texto.split()\n",
    "    if len(palabras) < 3:  # Frase muy corta\n",
    "        return \"Alerta: Frase demasiado corta. Posible dificultad para hablar.\"\n",
    "\n",
    "    # Detectar repeticiones de palabras exactas o similares\n",
    "    repeticiones = {}\n",
    "    for i in range(len(palabras)):\n",
    "        palabra_actual = palabras[i]\n",
    "        if palabra_actual in repeticiones:\n",
    "            repeticiones[palabra_actual] += 1\n",
    "        else:\n",
    "            # Verificar si hay palabras similares ya registradas\n",
    "            for palabra_registrada in repeticiones:\n",
    "                if fuzz.ratio(palabra_actual, palabra_registrada) > 80:  # Umbral de similitud\n",
    "                    repeticiones[palabra_registrada] += 1\n",
    "                    break\n",
    "            else:\n",
    "                repeticiones[palabra_actual] = 1\n",
    "\n",
    "    for palabra, count in repeticiones.items():\n",
    "        if count > 3:  # Palabra repetida más de 3 veces\n",
    "            return f\"Alerta: Palabra '{palabra}' repetida {count} veces. Posible dificultad para hablar.\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def analizar_coherencia(texto):\n",
    "    doc = nlp(texto)\n",
    "    \n",
    "    # Verificar si la oración tiene un verbo\n",
    "    tiene_verbo = any(token.pos_ == \"VERB\" for token in doc)\n",
    "    \n",
    "    # Verificar si la oración tiene un sujeto\n",
    "    tiene_sujeto = any(token.dep_ == \"nsubj\" for token in doc)\n",
    "    \n",
    "    # Verificar si la oración tiene un objeto (opcional)\n",
    "    tiene_objeto = any(token.dep_ in (\"obj\", \"dobj\") for token in doc)\n",
    "    \n",
    "    # Verificar si la oración es demasiado corta (menos de 3 palabras)\n",
    "    es_muy_corta = len(doc) < 3\n",
    "    \n",
    "    # Verificar si la oración tiene una estructura básica (sujeto + verbo)\n",
    "    es_coherente = tiene_verbo and tiene_sujeto and not es_muy_corta\n",
    "    \n",
    "    if not es_coherente:\n",
    "        return \"Alerta: La frase no parece tener una estructura coherente.\"\n",
    "    return \"La frase parece coherente.\"\n",
    "\n",
    "\n",
    "cap = None\n",
    "camara_encendida = False\n",
    "\n",
    "class EnhancedCameraApp:\n",
    "    def __init__(self, window, window_label, alertas_text):\n",
    "        self.window = window\n",
    "        self.window_label = window_label\n",
    "        self.alertas_text = alertas_text\n",
    "        self.video_source = 0\n",
    "        self.vid = None\n",
    "        self.is_camera_on = False\n",
    "        self.audio = pyaudio.PyAudio()\n",
    "        self.muted = False\n",
    "        self.tts_engine = pyttsx3.init()\n",
    "        self.voices = self.tts_engine.getProperty('voices')\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.microphone = sr.Microphone()\n",
    "        self.is_listening = False\n",
    "        self.setup_ui()\n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        # Detener el reconocimiento de voz y la cámara al cerrar la ventana\n",
    "        self.stop_listening()\n",
    "        self.stop_camera()\n",
    "\n",
    "    def stop_listening(self):\n",
    "        if self.is_listening:\n",
    "            self.is_listening = False  # Detener el hilo de reconocimiento de voz\n",
    "            self.btn_listen.config(text=\"Iniciar Reconocimiento\")\n",
    "\n",
    "    def setup_ui(self):\n",
    "        control_frame = ttk.Frame(self.window, style = \"Custom.TFrame\")\n",
    "        control_frame.pack(pady=10)\n",
    "\n",
    "        self.btn_frame = ttk.Frame(self.window, style = \"Custom.TFrame\")\n",
    "        self.btn_frame.pack(pady=10)\n",
    "\n",
    "        self.btn_start = tk.Button(\n",
    "            self.btn_frame,\n",
    "            text=\"Iniciar Cámara\",\n",
    "            command=self.start_camera,\n",
    "            font = (\"Times New Roman\", 16)\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.btn_start.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_stop = tk.Button(\n",
    "            self.btn_frame,\n",
    "            text=\"Detener Cámara\",\n",
    "            command=self.stop_camera,\n",
    "            state=tk.DISABLED,\n",
    "            font = (\"Times New Roman\", 16)\n",
    "            )\n",
    "        \n",
    "        self.btn_stop.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_mute = tk.Button(\n",
    "            self.btn_frame,\n",
    "            text=\"Silenciar\",\n",
    "            command=self.toggle_mute,\n",
    "            font = (\"Times New Roman\", 16)\n",
    "            )\n",
    "        self.btn_mute.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_listen = tk.Button(\n",
    "            self.btn_frame,\n",
    "            text=\"Iniciar Reconocimiento\",\n",
    "            command=self.toggle_listen,\n",
    "            font = (\"Times New Roman\", 16)\n",
    "            )\n",
    "        self.btn_listen.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.window, width=640, height=480, bg = COLOR_FONDO_PRINCIPAL)\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def start_camera(self):\n",
    "        global cap, camara_encendida, monitoreo_activo  # Acceder a las variables globales\n",
    "        if not self.is_camera_on:\n",
    "            self.vid = cv2.VideoCapture(self.video_source)\n",
    "            if not self.vid.isOpened():\n",
    "                print(\"Error: No se pudo abrir la cámara.\")\n",
    "                return\n",
    "            self.is_camera_on = True\n",
    "            cap = self.vid  # Actualizar la variable global `cap`\n",
    "            camara_encendida = True  # Actualizar el estado de la cámara\n",
    "            activar_monitoreo(True)  # Activar el monitoreo\n",
    "            self.update_camera()\n",
    "            self.btn_start.config(state=tk.DISABLED)\n",
    "            self.btn_stop.config(state=tk.NORMAL)\n",
    "\n",
    "# Modificar la función stop_camera para desactivar el monitoreo\n",
    "    def stop_camera(self):\n",
    "        global cap, camara_encendida, monitoreo_activo  # Acceder a las variables globales\n",
    "        if self.is_camera_on:\n",
    "            self.is_camera_on = False\n",
    "            self.vid.release()\n",
    "            cap = None  # Limpiar la variable global `cap`\n",
    "            camara_encendida = False  # Actualizar el estado de la cámara\n",
    "            activar_monitoreo(False)  # Desactivar el monitoreo\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.btn_start.config(state=tk.NORMAL)\n",
    "            self.btn_stop.config(state=tk.DISABLED)\n",
    "\n",
    "    def toggle_mute(self):\n",
    "        self.muted = not self.muted\n",
    "        self.btn_mute.config(text=\"Activar sonido\" if self.muted else \"Silenciar\")\n",
    "\n",
    "    def update_camera(self):\n",
    "        if self.is_camera_on:\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                img = Image.fromarray(rgb)\n",
    "                imgtk = ImageTk.PhotoImage(image=img)\n",
    "                self.canvas.imgtk = imgtk\n",
    "                self.canvas.create_image(0, 0, anchor=tk.NW, image=imgtk)\n",
    "            self.window.after(30, self.update_camera)\n",
    "\n",
    "    def toggle_listen(self):\n",
    "        global reconocimiento_voz_activo\n",
    "        if not self.is_listening:\n",
    "            self.is_listening = True\n",
    "            reconocimiento_voz_activo = True  # Activar el reconocimiento de voz\n",
    "            activar_monitoreo(True)  # Activar el monitoreo\n",
    "            self.btn_listen.config(text=\"Detener Reconocimiento\")\n",
    "            threading.Thread(target=self.recognize_speech, daemon=True).start()\n",
    "        else:\n",
    "            self.is_listening = False\n",
    "            reconocimiento_voz_activo = False  # Desactivar el reconocimiento de voz\n",
    "            activar_monitoreo(False)  # Desactivar el monitoreo\n",
    "            self.btn_listen.config(text=\"Iniciar Reconocimiento\")\n",
    "    def recognize_speech(self):\n",
    "        with self.microphone as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source, duration=2)\n",
    "            if app_running:\n",
    "                self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Sistema listo para escuchar...\\n\")\n",
    "                self.window.after(0, self.alertas_text.see, tk.END)\n",
    "\n",
    "            while self.is_listening and app_running:  # Verificar si la aplicación sigue en ejecución\n",
    "                try:\n",
    "                    inicio = time.time()\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Escuchando...\\n\")\n",
    "                        self.window.after(0, self.alertas_text.see, tk.END)\n",
    "\n",
    "                # Escuchar el audio desde el micrófono\n",
    "                    audio = self.recognizer.listen(source, timeout=5)\n",
    "                    fin = time.time()\n",
    "                    tiempo_transcurrido = fin - inicio\n",
    "\n",
    "                # Guardar el audio en un archivo temporal\n",
    "                    with open(\"temp_audio.wav\", \"wb\") as f:\n",
    "                        f.write(audio.get_wav_data())\n",
    "\n",
    "                # Filtrar el ruido del audio\n",
    "                    audio_filtrado_path = filtrar_ruido(\"temp_audio.wav\")\n",
    "\n",
    "                # Transcribir el audio filtrado\n",
    "                    texto = self.recognizer.recognize_google(audio_filtrado_path, language=\"es-ES\")\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.display_recognized_text, texto)\n",
    "\n",
    "                # Analizar fluidez y coherencia\n",
    "                    alerta_fluidez = analizar_fluidez(texto, tiempo_transcurrido)\n",
    "                    if alerta_fluidez and app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] {alerta_fluidez}\\n\")\n",
    "                        self.alertas_text.see(tk.END)\n",
    "\n",
    "                # Detectar pausas largas\n",
    "                    duracion_pausas = detectar_pausas_largas(audio_filtrado_path)\n",
    "                    if duracion_pausas > 4.0:  # Umbral de pausas largas\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Alerta: Pausas largas detectadas ({duracion_pausas:.1f} segundos).\\n\")\n",
    "                        self.alertas_text.see(tk.END)\n",
    "\n",
    "                except sr.UnknownValueError:\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] No se pudo entender el audio. Por favor, repite.\\n\")\n",
    "                        self.window.after(0, self.alertas_text.see, tk.END)\n",
    "                except sr.RequestError as e:\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Error en la solicitud al servicio de reconocimiento: {e}\\n\")\n",
    "                        self.window.after(0, self.alertas_text.see, tk.END)\n",
    "                except sr.WaitTimeoutError:\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Tiempo de espera agotado. Intenta de nuevo.\\n\")\n",
    "                        self.window.after(0, self.alertas_text.see, tk.END)\n",
    "                except Exception as e:\n",
    "                    if app_running:\n",
    "                        self.window.after(0, self.alertas_text.insert, tk.END, f\"[{datetime.now()}] Error inesperado: {e}\\n\")\n",
    "                        self.window.after(0, self.alertas_text.see, tk.END)\n",
    "\n",
    "\n",
    "    def display_recognized_text(self, text):\n",
    "        self.alertas_text.insert(tk.END, f\"[Voz Detectada] {text}\\n\")\n",
    "        self.alertas_text.see(tk.END)\n",
    "\n",
    "# Función para detectar actividad física\n",
    "prev_frame = None\n",
    "def detectar_movimiento():\n",
    "    global prev_frame, cap\n",
    "    if not camara_encendida or cap is None:\n",
    "        return False\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return False\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    if prev_frame is None:\n",
    "        prev_frame = gray\n",
    "        return False\n",
    "    frame_delta = cv2.absdiff(prev_frame, gray)\n",
    "    prev_frame = gray\n",
    "    movimiento = np.sum(frame_delta) > 500000  # Umbral de cambio en píxeles\n",
    "    return movimiento\n",
    "\n",
    "\n",
    "\n",
    "def detectar_emocion():\n",
    "    global cap\n",
    "    if not camara_encendida or cap is None:\n",
    "        return \"No se detecta cámara\"\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return \"No se pudo capturar imagen\"\n",
    "    \n",
    "    try:\n",
    "        # Redimensionar la imagen al tamaño esperado por el modelo (224x224)\n",
    "        resized = cv2.resize(frame, (224, 224))\n",
    "        \n",
    "        # Convertir la imagen a un array y normalizarla\n",
    "        resized = resized / 255.0\n",
    "        \n",
    "        # Expandir las dimensiones para que coincidan con la entrada del modelo\n",
    "        resized = np.expand_dims(resized, axis=0)\n",
    "        \n",
    "        # Predecir la emoción\n",
    "        predicciones = emociones_model.predict(resized)\n",
    "        \n",
    "        # Imprimir las predicciones para depuración\n",
    "        print(\"Predicciones:\", predicciones)\n",
    "        \n",
    "        # Obtener la emoción predicha (índice con la probabilidad más alta)\n",
    "        emocion_predicha = np.argmax(predicciones, axis=1)[0]\n",
    "        emociones = [\"Enojo\", \"Feliz\", \"Tristeza\", \"Sorpresa\", \"Neutral\"]\n",
    "        if emocion_predicha >= len(emociones):\n",
    "            return f\"Error: Índice de emoción fuera de rango ({emocion_predicha})\"\n",
    "        \n",
    "        # Obtener la emoción detectada\n",
    "        emocion_detectada = emociones[emocion_predicha]\n",
    "        \n",
    "        return f\"Emoción detectada: {emocion_detectada}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error al detectar emoción: {str(e)}\"\n",
    "\n",
    "# Configuración de reconocimiento de voz\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def detectar_cambios_habla():\n",
    "    try:\n",
    "        with sr.Microphone() as source:\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            try:\n",
    "                inicio = time.time()  # Registrar el tiempo de inicio\n",
    "                audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)\n",
    "                fin = time.time()  # Registrar el tiempo de finalización\n",
    "                tiempo_transcurrido = fin - inicio  # Calcular el tiempo transcurrido\n",
    "\n",
    "                texto = recognizer.recognize_google(audio, language=\"es-ES\")\n",
    "                \n",
    "                # Analizar fluidez y coherencia del habla\n",
    "                alerta_fluidez = analizar_fluidez(texto, tiempo_transcurrido)  # Pasar tiempo_transcurrido\n",
    "                if alerta_fluidez:\n",
    "                    return alerta_fluidez\n",
    "                \n",
    "                # Analizar coherencia semántica (opcional)\n",
    "                alerta_coherencia = analizar_coherencia(texto)\n",
    "                if alerta_coherencia:\n",
    "                    return alerta_coherencia\n",
    "                \n",
    "                return texto\n",
    "            except sr.WaitTimeoutError:\n",
    "                return \"Alerta: No se detectó sonido en el tiempo esperado.\"\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Alerta: No se detectó habla.\"\n",
    "            except sr.RequestError:\n",
    "                return \"Alerta: Error en reconocimiento.\"\n",
    "    except OSError:\n",
    "        return \"Alerta: No se detecta micrófono, no se puede realizar monitoreo del habla.\"\n",
    "\n",
    "# Variable global para controlar el estado del monitoreo\n",
    "monitoreo_activo = False\n",
    "app_running = True\n",
    "reconocimiento_voz_activo = False\n",
    "\n",
    "# Función para activar/desactivar el monitoreo\n",
    "def activar_monitoreo(estado):\n",
    "    global monitoreo_activo\n",
    "    monitoreo_activo = estado\n",
    "    \n",
    "\n",
    "# Monitoreo en tiempo real\n",
    "def monitorear_paciente():\n",
    "    global app_running, camara_encendida, reconocimiento_voz_activo\n",
    "    while app_running:  # Solo monitorear si la aplicación está en ejecución\n",
    "        if monitoreo_activo and camara_encendida:  # Solo monitorear si la cámara está encendida\n",
    "            actividad_fisica = detectar_movimiento()\n",
    "            habla = \"\"\n",
    "            if reconocimiento_voz_activo:  # Solo monitorear el habla si el reconocimiento de voz está activo\n",
    "                habla = detectar_cambios_habla()\n",
    "            emocion = detectar_emocion()\n",
    "            alertas = []\n",
    "            \n",
    "            if not actividad_fisica:\n",
    "                alertas.append(\"Alerta: Baja actividad física detectada.\")\n",
    "            if reconocimiento_voz_activo and \"Alerta\" in habla:  # Verificar si hay una alerta en el habla\n",
    "                alertas.append(habla)\n",
    "            \n",
    "            alertas.append(emocion)\n",
    "            \n",
    "            if app_running:  # Verificar si la ventana todavía está abierta\n",
    "                for alerta in alertas:\n",
    "                    alertas_text.config(state=tk.NORMAL)  # Habilitar la edición temporalmente\n",
    "                    alertas_text.insert(tk.END, f\"[{datetime.now()}] {alerta}\\n\")\n",
    "                    alertas_text.see(tk.END)\n",
    "                    alertas_text.config(state=tk.DISABLED)  # Deshabilitar la edición\n",
    "        \n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Función para predecir\n",
    "def seleccionar_imagen():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    title=\"Selecciona una imagen\",\n",
    "    filetypes=((\"Archivos de imagen\", \".jpg *.jpeg *.png\"), (\"Todos los archivos\", \".*\"))\n",
    "    return file_path\n",
    "\n",
    "def predecir_imagen(file_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(150, 150))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediccion = model.predict(img)\n",
    "    clase_predicha = np.argmax(prediccion, axis=1)\n",
    "    return clase_predicha[0]\n",
    "\n",
    "def predecir_y_mostrar():\n",
    "    file_path = seleccionar_imagen()\n",
    "    if file_path:\n",
    "\n",
    "        ### Cargar Imágen Seleccionada ###\n",
    "\n",
    "        img = Image.open(file_path)\n",
    "\n",
    "        ### Redimensionar la imágen para que quepa en la interfaz ###\n",
    "        img = img.resize((300, 300), Image.Resampling.LANCZOS)\n",
    "\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "        #Mostrar la Imágen en el widget de resultado\n",
    "        imagen_label.config(image = img_tk)\n",
    "\n",
    "        ### Mantener una referencia para evitar que la imágen sea eliminada por el recolector de basura###\n",
    "        imagen_label.image = img_tk\n",
    "    \n",
    "    \n",
    "        if file_path:\n",
    "            clase_predicha = predecir_imagen(file_path)\n",
    "        if clase_predicha == 0:\n",
    "            resultado = \"La imagen proporcionada pertenece a una persona que se encuentra en la etapa leve del alzheimer.\\n Se sugiere que opte por participar en actividades cognitivas y físicas para estimular el cerebro.\\n Consultar regularmente in médico especializado en neurología.\\n  Se observa una disminución en el volumen del tejido cerebral, especialmente en áreas como el hipocampo (crucial para la memoria) y la corteza cerebral. Esta atrofia es un indicador clave de la enfermedad de Alzheimer\"\n",
    "        elif clase_predicha == 1:\n",
    "            resultado = \"La imagen proporcionada pertenece a una persona que se encuentra en la etapa avanzada del alzheimer. \\n Se observa una atrofia cerebral más pronunciada. \\n Los ventrículos están más agrandados y la corteza cerebral muestra una mayor pérdida de volumen.\\n Se recomienda evaluaciones médicas de forma frecuente\"\n",
    "        elif clase_predicha == 2:\n",
    "            resultado = \"La imagen proporcionada pertenece a una persona que no posee alzheimer. \\n  En general, la estructura cerebral parece estar dentro de los límites normales para la edad de la persona. \\n No se observa una atrofia cerebral significativa. El volumen del tejido cerebral parece conservado.\"\n",
    "        elif clase_predicha == 3:\n",
    "            resultado = \"La imagen proporcionada pertenece a una persona que puede tener indicios de padecer alzheimer. \\n Se observa que el patrón de atrofia es consistente con la enfermedad de Alzheimer en una etapa muy temprana. Por lo tanto, existe una posibilidad de que esta persona padezca de alzheimer \"\n",
    "        else:\n",
    "            resultado = \"La imagen proporcionada es incorrecta.\"\n",
    "        \n",
    "        resultado_text.config(state = tk.NORMAL)\n",
    "        resultado_text.delete(1.0, tk.END)\n",
    "\n",
    "# Calcular el número de líneas vacías necesarias para centrar verticalmente\n",
    "        ### Mostrar el resultado en el widget de texto ###\n",
    "        resultado_text.config(state = tk.NORMAL)\n",
    "        resultado_text.delete(1.0, tk.END)  \n",
    "\n",
    "        # Calcular el número de líneas vacías necesarias para centrar verticalmente\n",
    "        num_lineas = resultado_text.winfo_height() // resultado_text.dlineinfo(\"@0,0\")[3]  # Altura en líneas\n",
    "        texto_lineas = resultado.count(\"\\n\") + 1  # Número de líneas del texto\n",
    "        lineas_vacias = (num_lineas - texto_lineas) // 2  # Líneas vacías antes del texto\n",
    "\n",
    "        # Insertar líneas vacías antes del texto\n",
    "        resultado_text.insert(tk.END, \"\\n\" * lineas_vacias)\n",
    "\n",
    "        resultado_text.insert(tk.END, resultado, \"centrado\")\n",
    "\n",
    "        # Insertar líneas vacías después del texto\n",
    "        resultado_text.insert(tk.END, \"\\n\" * lineas_vacias)\n",
    "\n",
    "        resultado_text.config(state=tk.DISABLED)\n",
    "\n",
    "# ==================================================\n",
    "# Interfaz gráfica\n",
    "# ==================================================\n",
    "\n",
    "ventana = tk.Tk()\n",
    "ventana.title(\"Memory Vision\")\n",
    "ventana.geometry(\"800x600\")\n",
    "ventana.configure(bg=COLOR_FONDO_PRINCIPAL)\n",
    "\n",
    "\n",
    "def on_close():\n",
    "    global app_running\n",
    "    app_running = False  # Detener el hilo de monitoreo\n",
    "    camera_app.stop_listening()  # Detener el reconocimiento de voz\n",
    "    camera_app.stop_camera()  # Detener la cámara\n",
    "    ventana.destroy()\n",
    "\n",
    "\n",
    "# Vincular el cierre de la ventana a la función on_close\n",
    "ventana.protocol(\"WM_DELETE_WINDOW\", on_close)\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "\n",
    "style.configure(\"Custom.TFrame\", background=COLOR_FONDO_PRINCIPAL)\n",
    "\n",
    "style.configure(\"Large.TButton\",\n",
    "                font = (\"Times New Roman\", 16)\n",
    "                )\n",
    "\n",
    "style.configure(\"TEntry\", font = (\"Times New Roman\", 16), background = \"white\", foreground = COLOR_TEXTO_PRINCIPAL)\n",
    "\n",
    "style.configure(\"TText\", font = (\"Times New Roman\", 16), background = \"white\", foreground = COLOR_TEXTO_PRINCIPAL)\n",
    "\n",
    "style.configure(\"TLabel\", font = (\"Times New Roman\", 16),  background = COLOR_FONDO_PRINCIPAL, foreground = COLOR_TEXTO_PRINCIPAL)\n",
    "\n",
    "notebook = ttk.Notebook(ventana)\n",
    "notebook.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "### Pestaña Monitoreo ###\n",
    "monitoreo_frame = ttk.Frame(notebook, style = \"Custom.TFrame\")\n",
    "notebook.add(monitoreo_frame, text=\"Monitoreo\")\n",
    "\n",
    "alertas_frame = tk.LabelFrame(\n",
    "    monitoreo_frame,\n",
    "    text=\"Alertas\",\n",
    "    font = (\"Times New Roman\", 25)\n",
    "    )\n",
    "alertas_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "\n",
    "alertas_text = tk.Text(\n",
    "    alertas_frame,\n",
    "    height=7,\n",
    "    width=40,\n",
    "    font = (\"Times New Roman\", 20)\n",
    "    )\n",
    "alertas_text.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "alertas_text.config(state = \"disabled\")\n",
    "\n",
    "camara_frame = ttk.Frame(monitoreo_frame)\n",
    "camara_frame.pack(pady=5)\n",
    "\n",
    "camara_label = ttk.Label(camara_frame)\n",
    "camara_label.pack()\n",
    "\n",
    "camera_app = EnhancedCameraApp(camara_frame, camara_label, alertas_text)\n",
    "\n",
    "### Pestaña Chatbot ###\n",
    "chatbot_frame = tk.Frame(notebook)\n",
    "notebook.add(chatbot_frame, text=\"Chatbot\")\n",
    "\n",
    "chatbot_system = ChatbotApp(chatbot_frame)\n",
    "\n",
    "### Pestaña Predicción ###\n",
    "prediccion_frame = ttk.Frame(notebook)\n",
    "notebook.add(prediccion_frame, text=\"Predicción\")\n",
    "\n",
    "pred_frame = tk.LabelFrame(prediccion_frame, text=\"Predicción de la imagen\", font = (\"Times New Roman\", 25))\n",
    "pred_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n",
    "\n",
    "predecir_button = tk.Button(pred_frame, text=\"Seleccionar Imagen y Predecir\", command=predecir_y_mostrar, font = (\"Times New Roman\", 16))\n",
    "predecir_button.pack(pady=5)\n",
    "\n",
    "imagen_label = tk.Label(pred_frame)\n",
    "imagen_label.pack(pady = 10)\n",
    "\n",
    "resultado_text = tk.Text(pred_frame, height=25, width=200, font = (\"Times New Roman\", 20))\n",
    "resultado_text.pack(padx=10, pady=70)\n",
    "\n",
    "resultado_text.tag_configure(\"centrado\", justify=\"center\")\n",
    "\n",
    "### Habilitar edición temporalmente ###\n",
    "resultado_text.config(state=\"normal\")\n",
    "\n",
    "### Volver a deshabilitar ###\n",
    "resultado_text.config(state=\"disabled\")\n",
    "\n",
    "# Iniciar monitoreo en segundo plano\n",
    "monitoreo_thread = threading.Thread(target=monitorear_paciente, daemon=True)\n",
    "monitoreo_thread.start()\n",
    "ventana.protocol(\"WM_DELETE_WINDOW\", on_close)\n",
    "ventana.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
